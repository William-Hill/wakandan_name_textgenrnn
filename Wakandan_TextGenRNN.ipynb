{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wakandan_TextGenRNN",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/William-Hill/wakandan_name_textgenrnn/blob/master/Wakandan_TextGenRNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvkRmNPLudrj",
        "colab_type": "text"
      },
      "source": [
        "We are going to use a character-based Recurrent Neural Network (RNN) to generate new Wakandan names using a dataset of existing Wakandan names.\n",
        "\n",
        "In order to do this, we are going to use several Data Science techniques in addition to using deep learning to accomplish this task.  We will use the OSEMN framework that has the following steps:\n",
        "\n",
        "\n",
        "\n",
        "1.   Obtain Data\n",
        "2.   Scrub Data\n",
        "3.   Explore Data\n",
        "4.   Model Data\n",
        "5.   Interpret Data\n",
        "\n",
        "![OSEMN_Framework_Diagram](https://miro.medium.com/max/3870/1*eE8DP4biqtaIK3aIy1S2zA.png)\n",
        "\n",
        "\n",
        "\n",
        "Note: Enable GPU acceleration to execute this notebook faster. In Colab: *Runtime > Change runtime type > Hardware acclerator > GPU*. If running locally make sure TensorFlow version >= 1.11."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7r6lHy1vu2D",
        "colab_type": "text"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kHdxYtEujYH",
        "colab_type": "text"
      },
      "source": [
        "## Install TensorFlow and other dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0GZXh1ku3YC",
        "colab_type": "text"
      },
      "source": [
        "We are going to use the `textgenrnn` library to create our model. `textgenrnn` is a Python 3 module on top of Keras/TensorFlow for creating character level Recurrent Neural Networks (RNN)\n",
        "\n",
        "We will need to install `tensorflow` as `textgenrnn` depends on it.\n",
        "\n",
        "We install `bokeh` as well. `bokeh` is a Python library for interactive visualization that targets web browsers for representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qa6FOG1Rhhrv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install textgenrnn tensorflow-gpu bokeh scrapy plotly==4.1.0 gpt-2-simple"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou_JRmXfvqjo",
        "colab_type": "text"
      },
      "source": [
        "## Import dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOegxUnN1Oaz",
        "colab_type": "text"
      },
      "source": [
        "Next we'll import the dependencies we just installed along with some others that we'll need for our project."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_0A7EIgnST3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests, zipfile, io, glob, os, json\n",
        "from textgenrnn import textgenrnn\n",
        "from google.colab import files\n",
        "from datetime import datetime\n",
        "import scrapy\n",
        "from scrapy.crawler import CrawlerProcess\n",
        "import re\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vr-uvGiWDLWt",
        "colab_type": "text"
      },
      "source": [
        "# A Quick Experiment\n",
        "\n",
        "Before diving into OSEMN process to build our Wakandan Name Generator model, let's do a quick experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iVon6-G2hZX",
        "colab_type": "text"
      },
      "source": [
        "### Dataset from PyTorch RNN example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qk2v4tIH1pLG",
        "colab_type": "text"
      },
      "source": [
        "We are going to download an example dataset that is used in a tutorial for Facebook's Deep Learning framework, PyTorch.  This dataset is used in a tutorial similar to this one in that it demonstrates using a character level RNN to generate names.\n",
        "\n",
        "The data is stored as a zip file.  Let's download and extract it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYDhWbDxhoA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = requests.get(\"https://download.pytorch.org/tutorial/data.zip\")\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEiT2I3VFjHc",
        "colab_type": "text"
      },
      "source": [
        "### Explore the data\n",
        "\n",
        "Let's take a look at the contents of our data.\n",
        "\n",
        "The dataset consists of 18 text files containing surnames from 18 languages of origin.\n",
        "\n",
        "Since the names come from various languages, they are encoded as Unicode strings in order to support language specific symbols such as umlauts.  We will need to convert the Unicode strings to ASCII.\n",
        "\n",
        "We loop over the text files and add all the names for each language to a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDP2c_2QZF4d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def findFiles(path): \n",
        "  return glob.glob(path)\n",
        "\n",
        "print(findFiles('data/names/*.txt'))\n",
        "\n",
        "\n",
        "import unicodedata\n",
        "import string\n",
        "\n",
        "all_letters = string.ascii_letters + \" .,;'\"\n",
        "n_letters = len(all_letters)\n",
        "\n",
        "\n",
        "# Turn a Unicode string to plain ASCII, thanks to http://stackoverflow.com/a/518232/2809427\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "        and c in all_letters\n",
        "    )\n",
        "\n",
        "print(unicodeToAscii('Ślusàrski'))\n",
        "\n",
        "# Build the category_lines dictionary, a list of names per language\n",
        "category_lines = {}\n",
        "all_categories = []\n",
        "category_counts = {}\n",
        "\n",
        "# Read a file and split into lines\n",
        "def readLines(filename):\n",
        "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
        "    return [unicodeToAscii(line) for line in lines]\n",
        "\n",
        "for filename in findFiles('data/names/*.txt'):\n",
        "    category = os.path.splitext(os.path.basename(filename))[0]\n",
        "    all_categories.append(category)\n",
        "    lines = readLines(filename)\n",
        "    category_lines[category] = lines\n",
        "    category_counts[category] = len(lines)\n",
        "\n",
        "counts = category_counts.values()\n",
        "print(\"counts:\", counts)\n",
        "\n",
        "n_categories = len(all_categories)\n",
        "print(\"all_categories:\", all_categories)\n",
        "print(\"category_lines:\", category_lines)\n",
        "print(\"category_counts:\", category_counts)\n",
        "print(\"spanish count:\", len(category_lines[\"Spanish\"]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUWLXaHzZJyE",
        "colab_type": "text"
      },
      "source": [
        "###Visualize the data\n",
        "\n",
        "Let's plot the data to get a better look at it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qaf6wvPZZPGq",
        "colab_type": "text"
      },
      "source": [
        "#### Bar chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWhUsFpcZ9xW",
        "colab_type": "code",
        "outputId": "0a577fae-df73-4919-e9a5-de92c5e44bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        }
      },
      "source": [
        "from bokeh.io import show, output_file, output_notebook\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.models import HoverTool, ColumnDataSource\n",
        "\n",
        "output_notebook()\n",
        "output_file(\"bars.html\")\n",
        "\n",
        "counts = list(category_counts.values())\n",
        "countries = list(category_counts.keys())\n",
        "source = ColumnDataSource(data=dict(countries=countries, counts=counts))\n",
        "\n",
        "p = figure(x_range=countries, plot_height=250, title=\"Name Counts\",\n",
        "           toolbar_location=None, tools=\"\")\n",
        "p.sizing_mode = 'scale_width'\n",
        "\n",
        "p.vbar(x='countries', top='counts', width=0.9, source=source)\n",
        "p.add_tools(HoverTool(tooltips=[(\"Count\", \"@counts\")]))\n",
        "\n",
        "p.xgrid.grid_line_color = None\n",
        "p.y_range.start = 0\n",
        "\n",
        "show(p)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "(function(root) {\n",
              "  function now() {\n",
              "    return new Date();\n",
              "  }\n",
              "\n",
              "  var force = true;\n",
              "\n",
              "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
              "    root._bokeh_onload_callbacks = [];\n",
              "    root._bokeh_is_loading = undefined;\n",
              "  }\n",
              "\n",
              "  var JS_MIME_TYPE = 'application/javascript';\n",
              "  var HTML_MIME_TYPE = 'text/html';\n",
              "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
              "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
              "\n",
              "  /**\n",
              "   * Render data to the DOM node\n",
              "   */\n",
              "  function render(props, node) {\n",
              "    var script = document.createElement(\"script\");\n",
              "    node.appendChild(script);\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when an output is cleared or removed\n",
              "   */\n",
              "  function handleClearOutput(event, handle) {\n",
              "    var cell = handle.cell;\n",
              "\n",
              "    var id = cell.output_area._bokeh_element_id;\n",
              "    var server_id = cell.output_area._bokeh_server_id;\n",
              "    // Clean up Bokeh references\n",
              "    if (id != null && id in Bokeh.index) {\n",
              "      Bokeh.index[id].model.document.clear();\n",
              "      delete Bokeh.index[id];\n",
              "    }\n",
              "\n",
              "    if (server_id !== undefined) {\n",
              "      // Clean up Bokeh references\n",
              "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
              "      cell.notebook.kernel.execute(cmd, {\n",
              "        iopub: {\n",
              "          output: function(msg) {\n",
              "            var id = msg.content.text.trim();\n",
              "            if (id in Bokeh.index) {\n",
              "              Bokeh.index[id].model.document.clear();\n",
              "              delete Bokeh.index[id];\n",
              "            }\n",
              "          }\n",
              "        }\n",
              "      });\n",
              "      // Destroy server and session\n",
              "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
              "      cell.notebook.kernel.execute(cmd);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  /**\n",
              "   * Handle when a new output is added\n",
              "   */\n",
              "  function handleAddOutput(event, handle) {\n",
              "    var output_area = handle.output_area;\n",
              "    var output = handle.output;\n",
              "\n",
              "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
              "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
              "      return\n",
              "    }\n",
              "\n",
              "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
              "\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
              "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
              "      // store reference to embed id on output_area\n",
              "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
              "    }\n",
              "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
              "      var bk_div = document.createElement(\"div\");\n",
              "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
              "      var script_attrs = bk_div.children[0].attributes;\n",
              "      for (var i = 0; i < script_attrs.length; i++) {\n",
              "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
              "      }\n",
              "      // store reference to server id on output_area\n",
              "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
              "    }\n",
              "  }\n",
              "\n",
              "  function register_renderer(events, OutputArea) {\n",
              "\n",
              "    function append_mime(data, metadata, element) {\n",
              "      // create a DOM node to render to\n",
              "      var toinsert = this.create_output_subarea(\n",
              "        metadata,\n",
              "        CLASS_NAME,\n",
              "        EXEC_MIME_TYPE\n",
              "      );\n",
              "      this.keyboard_manager.register_events(toinsert);\n",
              "      // Render to node\n",
              "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
              "      render(props, toinsert[toinsert.length - 1]);\n",
              "      element.append(toinsert);\n",
              "      return toinsert\n",
              "    }\n",
              "\n",
              "    /* Handle when an output is cleared or removed */\n",
              "    events.on('clear_output.CodeCell', handleClearOutput);\n",
              "    events.on('delete.Cell', handleClearOutput);\n",
              "\n",
              "    /* Handle when a new output is added */\n",
              "    events.on('output_added.OutputArea', handleAddOutput);\n",
              "\n",
              "    /**\n",
              "     * Register the mime type and append_mime function with output_area\n",
              "     */\n",
              "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
              "      /* Is output safe? */\n",
              "      safe: true,\n",
              "      /* Index of renderer in `output_area.display_order` */\n",
              "      index: 0\n",
              "    });\n",
              "  }\n",
              "\n",
              "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
              "  if (root.Jupyter !== undefined) {\n",
              "    var events = require('base/js/events');\n",
              "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
              "\n",
              "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
              "      register_renderer(events, OutputArea);\n",
              "    }\n",
              "  }\n",
              "\n",
              "  \n",
              "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
              "    root._bokeh_timeout = Date.now() + 5000;\n",
              "    root._bokeh_failed_load = false;\n",
              "  }\n",
              "\n",
              "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
              "     \"<div style='background-color: #fdd'>\\n\"+\n",
              "     \"<p>\\n\"+\n",
              "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
              "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
              "     \"</p>\\n\"+\n",
              "     \"<ul>\\n\"+\n",
              "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
              "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
              "     \"</ul>\\n\"+\n",
              "     \"<code>\\n\"+\n",
              "     \"from bokeh.resources import INLINE\\n\"+\n",
              "     \"output_notebook(resources=INLINE)\\n\"+\n",
              "     \"</code>\\n\"+\n",
              "     \"</div>\"}};\n",
              "\n",
              "  function display_loaded() {\n",
              "    var el = document.getElementById(null);\n",
              "    if (el != null) {\n",
              "      el.textContent = \"BokehJS is loading...\";\n",
              "    }\n",
              "    if (root.Bokeh !== undefined) {\n",
              "      if (el != null) {\n",
              "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
              "      }\n",
              "    } else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(display_loaded, 100)\n",
              "    }\n",
              "  }\n",
              "\n",
              "\n",
              "  function run_callbacks() {\n",
              "    try {\n",
              "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
              "    }\n",
              "    finally {\n",
              "      delete root._bokeh_onload_callbacks\n",
              "    }\n",
              "    console.info(\"Bokeh: all callbacks have finished\");\n",
              "  }\n",
              "\n",
              "  function load_libs(js_urls, callback) {\n",
              "    root._bokeh_onload_callbacks.push(callback);\n",
              "    if (root._bokeh_is_loading > 0) {\n",
              "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
              "      return null;\n",
              "    }\n",
              "    if (js_urls == null || js_urls.length === 0) {\n",
              "      run_callbacks();\n",
              "      return null;\n",
              "    }\n",
              "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
              "    root._bokeh_is_loading = js_urls.length;\n",
              "    for (var i = 0; i < js_urls.length; i++) {\n",
              "      var url = js_urls[i];\n",
              "      var s = document.createElement('script');\n",
              "      s.src = url;\n",
              "      s.async = false;\n",
              "      s.onreadystatechange = s.onload = function() {\n",
              "        root._bokeh_is_loading--;\n",
              "        if (root._bokeh_is_loading === 0) {\n",
              "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
              "          run_callbacks()\n",
              "        }\n",
              "      };\n",
              "      s.onerror = function() {\n",
              "        console.warn(\"failed to load library \" + url);\n",
              "      };\n",
              "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
              "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "    }\n",
              "  };\n",
              "\n",
              "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n",
              "\n",
              "  var inline_js = [\n",
              "    function(Bokeh) {\n",
              "      Bokeh.set_log_level(\"info\");\n",
              "    },\n",
              "    \n",
              "    function(Bokeh) {\n",
              "      \n",
              "    },\n",
              "    function(Bokeh) {\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n",
              "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
              "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n",
              "    }\n",
              "  ];\n",
              "\n",
              "  function run_inline_js() {\n",
              "    \n",
              "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
              "      for (var i = 0; i < inline_js.length; i++) {\n",
              "        inline_js[i].call(root, root.Bokeh);\n",
              "      }} else if (Date.now() < root._bokeh_timeout) {\n",
              "      setTimeout(run_inline_js, 100);\n",
              "    } else if (!root._bokeh_failed_load) {\n",
              "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
              "      root._bokeh_failed_load = true;\n",
              "    } else if (force !== true) {\n",
              "      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n",
              "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
              "    }\n",
              "\n",
              "  }\n",
              "\n",
              "  if (root._bokeh_is_loading === 0) {\n",
              "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
              "    run_inline_js();\n",
              "  } else {\n",
              "    load_libs(js_urls, function() {\n",
              "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
              "      run_inline_js();\n",
              "    });\n",
              "  }\n",
              "}(window));"
            ],
            "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(null);\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.0.4.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.0.4.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.0.4.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(null)).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "  <div class=\"bk-root\" id=\"8ba3a8a7-cb14-4b17-9142-b5b437748ea6\" data-root-id=\"1003\"></div>\n"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "(function(root) {\n",
              "  function embed_document(root) {\n",
              "    \n",
              "  var docs_json = {\"6ccef432-75ee-4148-aead-9d092d15fc61\":{\"roots\":{\"references\":[{\"attributes\":{\"below\":[{\"id\":\"1013\",\"type\":\"CategoricalAxis\"}],\"left\":[{\"id\":\"1017\",\"type\":\"LinearAxis\"}],\"plot_height\":250,\"renderers\":[{\"id\":\"1013\",\"type\":\"CategoricalAxis\"},{\"id\":\"1016\",\"type\":\"Grid\"},{\"id\":\"1017\",\"type\":\"LinearAxis\"},{\"id\":\"1021\",\"type\":\"Grid\"},{\"id\":\"1026\",\"type\":\"GlyphRenderer\"}],\"sizing_mode\":\"scale_width\",\"title\":{\"id\":\"1002\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"1022\",\"type\":\"Toolbar\"},\"toolbar_location\":null,\"x_range\":{\"id\":\"1005\",\"type\":\"FactorRange\"},\"x_scale\":{\"id\":\"1009\",\"type\":\"CategoricalScale\"},\"y_range\":{\"id\":\"1007\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"1011\",\"type\":\"LinearScale\"}},\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{},\"id\":\"1033\",\"type\":\"CategoricalTickFormatter\"},{\"attributes\":{\"callback\":null,\"start\":0},\"id\":\"1007\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"1035\",\"type\":\"UnionRenderers\"},{\"attributes\":{},\"id\":\"1009\",\"type\":\"CategoricalScale\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"counts\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"countries\"}},\"id\":\"1024\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1036\",\"type\":\"Selection\"},{\"attributes\":{},\"id\":\"1011\",\"type\":\"LinearScale\"},{\"attributes\":{\"callback\":null,\"data\":{\"countries\":[\"Korean\",\"Russian\",\"Japanese\",\"Irish\",\"German\",\"Scottish\",\"Dutch\",\"Polish\",\"Spanish\",\"Greek\",\"Chinese\",\"French\",\"Vietnamese\",\"Czech\",\"Portuguese\",\"English\",\"Italian\",\"Arabic\"],\"counts\":[94,9408,991,232,724,100,297,139,298,203,268,277,73,519,74,3668,709,2000]},\"selected\":{\"id\":\"1036\",\"type\":\"Selection\"},\"selection_policy\":{\"id\":\"1035\",\"type\":\"UnionRenderers\"}},\"id\":\"1001\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"formatter\":{\"id\":\"1033\",\"type\":\"CategoricalTickFormatter\"},\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1014\",\"type\":\"CategoricalTicker\"}},\"id\":\"1013\",\"type\":\"CategoricalAxis\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"top\":{\"field\":\"counts\"},\"width\":{\"value\":0.9},\"x\":{\"field\":\"countries\"}},\"id\":\"1025\",\"type\":\"VBar\"},{\"attributes\":{},\"id\":\"1014\",\"type\":\"CategoricalTicker\"},{\"attributes\":{\"source\":{\"id\":\"1001\",\"type\":\"ColumnDataSource\"}},\"id\":\"1027\",\"type\":\"CDSView\"},{\"attributes\":{\"grid_line_color\":{\"value\":null},\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1014\",\"type\":\"CategoricalTicker\"}},\"id\":\"1016\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"1031\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"formatter\":{\"id\":\"1031\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1018\",\"type\":\"BasicTicker\"}},\"id\":\"1017\",\"type\":\"LinearAxis\"},{\"attributes\":{\"data_source\":{\"id\":\"1001\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"1024\",\"type\":\"VBar\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"1025\",\"type\":\"VBar\"},\"selection_glyph\":null,\"view\":{\"id\":\"1027\",\"type\":\"CDSView\"}},\"id\":\"1026\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"1018\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"1003\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"1018\",\"type\":\"BasicTicker\"}},\"id\":\"1021\",\"type\":\"Grid\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_multi\":null,\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1028\",\"type\":\"HoverTool\"}]},\"id\":\"1022\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"Count\",\"@counts\"]]},\"id\":\"1028\",\"type\":\"HoverTool\"},{\"attributes\":{\"plot\":null,\"text\":\"Name Counts\"},\"id\":\"1002\",\"type\":\"Title\"},{\"attributes\":{\"callback\":null,\"factors\":[\"Korean\",\"Russian\",\"Japanese\",\"Irish\",\"German\",\"Scottish\",\"Dutch\",\"Polish\",\"Spanish\",\"Greek\",\"Chinese\",\"French\",\"Vietnamese\",\"Czech\",\"Portuguese\",\"English\",\"Italian\",\"Arabic\"]},\"id\":\"1005\",\"type\":\"FactorRange\"}],\"root_ids\":[\"1003\"]},\"title\":\"Bokeh Application\",\"version\":\"1.0.4\"}};\n",
              "  var render_items = [{\"docid\":\"6ccef432-75ee-4148-aead-9d092d15fc61\",\"roots\":{\"1003\":\"8ba3a8a7-cb14-4b17-9142-b5b437748ea6\"}}];\n",
              "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
              "\n",
              "  }\n",
              "  if (root.Bokeh !== undefined) {\n",
              "    embed_document(root);\n",
              "  } else {\n",
              "    var attempts = 0;\n",
              "    var timer = setInterval(function(root) {\n",
              "      if (root.Bokeh !== undefined) {\n",
              "        embed_document(root);\n",
              "        clearInterval(timer);\n",
              "      }\n",
              "      attempts++;\n",
              "      if (attempts > 100) {\n",
              "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\");\n",
              "        clearInterval(timer);\n",
              "      }\n",
              "    }, 10, root)\n",
              "  }\n",
              "})(window);"
            ],
            "application/vnd.bokehjs_exec.v0+json": ""
          },
          "metadata": {
            "tags": [],
            "application/vnd.bokehjs_exec.v0+json": {
              "id": "1003"
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B30pJjr3aC-Q",
        "colab_type": "text"
      },
      "source": [
        "We can see that our data is not uniform (and has a large outlier in Russian names.....hmm, interesting 🤔)\n",
        "\n",
        "Let's visualize our data in a different way to see if we can get more insight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9m8-mPOaGF9",
        "colab_type": "text"
      },
      "source": [
        "#### Chloropleth\n",
        "\n",
        "Let's plot our data on a map to get a visual breakdown of the regions represented by the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1v7HAvWaShe",
        "colab_type": "text"
      },
      "source": [
        "First we will need to download some country shape files to create our map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG0DYJV-aeD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "r = requests.get(\"https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/110m/cultural/ne_110m_admin_0_countries.zip\")\n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stCUt2kPalcP",
        "colab_type": "text"
      },
      "source": [
        "Now let's create a CSV file with the countries in our dataset.  The CSV will create rows with the language's country (or countries) of origin, its ISO-3166 country code, and the count."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91614dGEagjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "country_codes = {\"Spanish\": \"ESP\", \"Japanese\": \"JPN\", \"Chinese\": \"CHN\", \"Czech\": \"CZE\", \n",
        "                 \"Portuguese\": \"PRT\", \"Scottish\": \"GBR\", \"English\": \"GBR\", \n",
        "                 \"Italian\": \"ITA\", \"Irish\": \"IRL\", \"Korean\": \"Kor\", \"German\": \n",
        "                 \"DEU\", \"Greek\": \"GRC\", \"French\": \"FRA\", \n",
        "                 \"Arabic\": [\"Jordan\", \"Palestine\", \"Syria\", \"Lebanon\", \"Morocco\", \"Mauritania\", \"Algeria\", \"Tunisia\", \"Libya\", \"Sudan\", \"Somalia\", \"Egypt\", \"Saudi Arabia\", \"Yemen\", \"Oman\", \"Qatar\", \"Bahrain\", \"Kuwait\", \"Comoros\", \"Iraq\", \"Djibouti\", \"United Arab Emirates\"],\n",
        "                 \"Russian\": \"RUS\", \"Polish\": \"POL\", \"Vietnamese\": \"VNM\", \"Dutch\": \"NLD\"\n",
        "                }\n",
        "\n",
        "import csv\n",
        "\n",
        "csv_columns = ['Language','Code','Count']\n",
        "\n",
        "try:\n",
        "    with open('name_count_by_language.csv', 'w') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
        "        writer.writeheader()\n",
        "        for key, value in category_counts.items():\n",
        "            writer.writerow({'Language': key, 'Code': country_codes[key], 'Count': value})\n",
        "except IOError:\n",
        "    print(\"I/O error\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91CfWj7na-pU",
        "colab_type": "text"
      },
      "source": [
        "Now we can plot the data on the map using Plotly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_4tfjU7a9y3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "\n",
        "# df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2014_world_gdp_with_codes.csv')\n",
        "df = pd.read_csv('name_count_by_language.csv')\n",
        "\n",
        "fig = go.Figure(data=go.Choropleth(\n",
        "    locations = df['Code'],\n",
        "    z = df['Count'],\n",
        "    text = df['Language'],\n",
        "    colorscale = 'Blues',\n",
        "    autocolorscale=False,\n",
        "    reversescale=True,\n",
        "    marker_line_color='darkgray',\n",
        "    marker_line_width=0.5,\n",
        "    colorbar_title = 'Names in Language',\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text='Names by Language',\n",
        "    geo=dict(\n",
        "        showframe=False,\n",
        "        showcoastlines=False,\n",
        "        projection_type='equirectangular'\n",
        "    ),\n",
        "    annotations = [dict(\n",
        "        x=0.55,\n",
        "        y=0.1,\n",
        "        xref='paper',\n",
        "        yref='paper',\n",
        "        text='Source: <a href=\"https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html\">\\\n",
        "            Facebook PyTorch Tutorials</a>',\n",
        "        showarrow = False\n",
        "    )]\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "al7Fe6g3EFvB",
        "colab_type": "text"
      },
      "source": [
        "### Bias in Data\n",
        "\n",
        "You may ask why we did that little experiment?  It was to demonstrate how data can be biased.  By visualizing the data from as a choropleth, we can see that virtually no names that native to the continent of Africa are represented."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTqNMn8E1eUX",
        "colab_type": "text"
      },
      "source": [
        "# Obtain Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEowvIBa2rdJ",
        "colab_type": "text"
      },
      "source": [
        "### Wakandan Name dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clkzVlHa2cgA",
        "colab_type": "text"
      },
      "source": [
        "We need to obtain our Wakandan name dataset.  We will use this dataset to create a name that is structurally similar to a known Wakandan name. \n",
        "\n",
        "The dataset will be split into male Wakandan name and female Wakandan names.  The dataset is split because Wakandan names usually have a certain format depending on gender.  A male Wakandan name typically begins with a consonant, then an apostrophe, then the rest of the name (for example T'Challa).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kpWCKrYHtBO",
        "colab_type": "text"
      },
      "source": [
        "### Scrape data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhGGkwqMHv5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NamesSpider(scrapy.Spider):\n",
        "    name = \"quotes\"\n",
        "    start_urls = [\n",
        "        'https://marvel.fandom.com/wiki/Category:Wakandans',\n",
        "        'https://marvel.fandom.com/wiki/Category:Wakandans?from=Shikona+%28Earth-161%29%0AShikona+%28Earth-161%29',\n",
        "        'https://marvel.fandom.com/wiki/Category:Wakandans?from=Zatama+%28Earth-616%29%0AZatama+%28Earth-616%29'\n",
        "    ]\n",
        "    \n",
        "    custom_settings = {\n",
        "        'FEED_FORMAT':'json',\n",
        "        'FEED_URI': 'names.json'\n",
        "    }\n",
        "\n",
        "    def parse(self, response):\n",
        "        wakandan_name_links = response.css(\n",
        "            \".category-page__member a::attr(href)\").getall()\n",
        "        for link in wakandan_name_links:\n",
        "            yield response.follow(link, self.parse_name)\n",
        "            # yield {\n",
        "            #     'text': quote.css('span.text::text').get(),\n",
        "            #     'author': quote.css('small.author::text').get(),\n",
        "            #     'tags': quote.css('div.tags a.tag::text').getall(),\n",
        "            # }\n",
        "        self.print_names()\n",
        "        \n",
        "        next_page = response.css(\".category-page__pagination-next a::attr('href')\")\n",
        "        if next_page:\n",
        "          print(\"Found link to next page\")\n",
        "          url = response.urljoin(next_page[0].extract())\n",
        "          yield scrapy.Request(url, self.parse)\n",
        "          #TODO: Try both of lines below\n",
        "#           self.parse(url)\n",
        "#           yield response.follow(url, self.parse)\n",
        "\n",
        "    def parse_name(self, response):\n",
        "        name = response.css(\n",
        "            'div[data-source=\"RealName\"] div::text').get().strip()\n",
        "        if not name:\n",
        "            name = response.css(\n",
        "                '.page-header__title::text').get().strip()\n",
        "        name = re.sub(r\" ?\\([^)]+\\)\", \"\", name)\n",
        "        scrape_gender = response.css('div[data-source=\"Gender\"] a::text').get()\n",
        "        yield {\n",
        "            'name': name,\n",
        "            'gender': scrape_gender,\n",
        "        }\n",
        "\n",
        "        \n",
        "process = CrawlerProcess({\n",
        "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
        "})\n",
        "\n",
        "process.crawl(NamesSpider)\n",
        "process.start() # the script will block here until the crawling is finished"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMSlWTJYfbzN",
        "colab_type": "text"
      },
      "source": [
        "# Scrub The Data\n",
        "\n",
        "Now that we have scraped the raw dataset from the wiki, we need to pre-process, or scrub, the data to prepare it for use with the model.\n",
        "\n",
        "We need to split the dataset by masculine names and feminine names"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SJUZq9sfunP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wakandan_masculine_names = set()\n",
        "wakandan_feminine_names = set()\n",
        "\n",
        "with open('names.json') as names:\n",
        "        name_data = json.load(names)\n",
        "\n",
        "    \n",
        "for name in name_data:\n",
        "  if name['gender'] == 'Female':\n",
        "    wakandan_feminine_names.add(name['name'])\n",
        "  else:\n",
        "    wakandan_masculine_names.add(name['name'])\n",
        "#   print(\"value:\", value)\n",
        "\n",
        "\n",
        "print(\"wakandan_masculine_names:\", wakandan_masculine_names)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLVpOt_RG6Yh",
        "colab_type": "text"
      },
      "source": [
        "# Explore The Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQArFpxViRN6",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the data\n",
        "\n",
        "Let's plot at the raw data split by gender."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7OphFw3h0R0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO: Make this a pie chart instead\n",
        "output_notebook()\n",
        "output_file(\"names_raw_data.html\")\n",
        "\n",
        "counts = [len(wakandan_masculine_names), len(wakandan_feminine_names)]\n",
        "gender = [\"masculine\", \"feminine\"]\n",
        "source = ColumnDataSource(data=dict(gender=gender, counts=counts))\n",
        "\n",
        "p = figure(x_range=gender, plot_height=250, title=\"Name Counts\",\n",
        "           toolbar_location=None, tools=\"\")\n",
        "p.sizing_mode = 'scale_width'\n",
        "\n",
        "p.vbar(x='gender', top='counts', width=0.9, source=source)\n",
        "p.add_tools(HoverTool(tooltips=[(\"Count\", \"@counts\")]))\n",
        "\n",
        "p.xgrid.grid_line_color = None\n",
        "p.y_range.start = 0\n",
        "\n",
        "show(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZQFyC8Dii8y",
        "colab_type": "text"
      },
      "source": [
        "We can see that the data is skewed towards masculine names.  Most real world data will not be uniform so this isn't very unusual (but could be a symptom of bias).\n",
        "\n",
        "\n",
        "There's still some scrubbing that we need to do before we can feed it to the model.\n",
        "\n",
        "The dataset is split into male Wakandan names and female Wakandan names.  The dataset is split because Wakandan names usually have a certain format depending on gender.  A male Wakandan name typically begins with a consonant, then an apostrophe, then the rest of the name (for example T'Challa).  \n",
        "\n",
        "However, there are outliers in our data. As new writers such as Ta'Nehisi Coates and Roxane Gay have expanded the Wakandan lore, the names have become less uniform.  For example, A'di is the niece of King T'Challa. She has a name that is typically suggests that she identifies as a male.  She's still more exception than rule though.  \n",
        "\n",
        "For this project, we are going to normalize the data in that male and female names follow the established patterns for simplicity's sake.  We will scrub away any names that don't conform to the patterns for both datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6U8V-S1p0kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "wakandan_masculine_names = [x for x in wakandan_masculine_names if \"'\" in x]\n",
        "print(\"wakandan_masculine_names:\", wakandan_masculine_names)\n",
        "print(\"wakandan_masculine_names:\", len(wakandan_masculine_names))\n",
        "wakandan_feminine_names = [x for x in wakandan_feminine_names if \"'\" not in x]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5HSagCdHNM2",
        "colab_type": "text"
      },
      "source": [
        "# Model the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6QrM7KM20yA",
        "colab_type": "text"
      },
      "source": [
        "## Create `textgenrnn` object"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voAqdTxT29Si",
        "colab_type": "text"
      },
      "source": [
        "Before we train the model, we must create an instance of the `textgenrnn` class.\n",
        "\n",
        "We can provide a `name` argument to the class that it will use to save the model to a file after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15wn8x0l3Wxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'wakandan_names'   # change to set file name of resulting trained models/texts\n",
        "\n",
        "textgen = textgenrnn(name=model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR8rCmk53bSs",
        "colab_type": "text"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heqvb_ux3gXc",
        "colab_type": "text"
      },
      "source": [
        "Now we are ready to train the model on the dataset.\n",
        "\n",
        "We use the `train_on_texts` method to train the model on our Wakanda name dataset.  `textgenrnn` comes with a pre-trained model out of the box that we could use for Transfer Learning, but we are going to train our model from scratch so we pass a value of True to the `new_model` argument.\n",
        "\n",
        "We are training for 60 epochs with a test generation output occurring at every 5th epoch.\n",
        "\n",
        "We set our `train_size` and `dropout` to 0.7 and 0.2, respectively to help combat overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQhzsIL7qScn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textgen.reset()\n",
        "textgen.train_on_texts(wakandan_masculine_names, new_model=True, num_epochs=60,  gen_epochs=5, train_size=0.7, dropout=0.2) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmlMa71BISv9",
        "colab_type": "text"
      },
      "source": [
        "# Interpret the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egmyjfE54dws",
        "colab_type": "text"
      },
      "source": [
        "## Generate names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tb-FIy344gtb",
        "colab_type": "text"
      },
      "source": [
        "Our model is now trained on the dataset and can be used to generate new names.\n",
        "\n",
        "The model isn't perfect as it will generate some names that are already in the dataset (a sign of slight overfitting) or it will generate some names that don't quite confirm to the semantic structure of a typical Wakandan name.  But for a model that was trained on a **really small** dataset for under 5 minutes, it does pretty good!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzzeJlOuq0PM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "textgen.generate()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PmYEq3mJdpF",
        "colab_type": "text"
      },
      "source": [
        "## Measure Fitness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OQYn6uCJhRG",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we get some duplicate names from the dataset generating when using our model.  This is a symptom of overfitting.  But since our dataset is so small, that is somewhat expected.  \n",
        "\n",
        "But we still would like a way to measure how good our model is at generating new names.  One way we could do this is with a simple brute force measurement.  We can measure the number of times our model generates a unique name out of 100 invocations to measure the percentage. We don't the name generated to just be unique, but also semantically similar to the names in dataset on which the model was trained.  We can use Levenshtein distance to measure how close the generated name is to a name in the dataset.  We can experiment with the similarity threshold, but we arbitrarily chose 70% as a starting point."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9uxi6lCKrcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO: write fitness test function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYVBJkSUnQcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# file_path = 'data/names/Russian.txt'\n",
        "\n",
        "# textgen.reset()\n",
        "# textgen.train_from_file(file_path, new_model=True, num_epochs=10, gen_epochs=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xo79aDwV5AT0",
        "colab_type": "text"
      },
      "source": [
        "## Save results to a file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ba_3BhZM5FTD",
        "colab_type": "text"
      },
      "source": [
        "We can continously call the `generate` function to generate names to the console.\n",
        "\n",
        "We can also generate an arbitrary number of names and write them to a file.\n",
        "\n",
        "We use the `generate_to_file` function to do so.  We can pass in the number of names we want to generate to the `n` parameter (cringes at single letter variable name).\n",
        "\n",
        "We could also pass in a string to the `prefix` parameter to act as a seed for generating our name.\n",
        "\n",
        "We then use Colab's `file` API to download our file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qrkWbzLv1fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this temperature schedule cycles between 1 very unexpected token, 1 unexpected token, 2 expected tokens, repeat.\n",
        "# changing the temperature schedule can result in wildly different output!\n",
        "temperature = [1.0, 0.5, 0.2, 0.2]   \n",
        "prefix = None   # if you want each generated text to start with a given seed text\n",
        "\n",
        "# if train_cfg['line_delimited']:\n",
        "#   n = 1000\n",
        "#   max_gen_length = 60 if model_cfg['word_level'] else 300\n",
        "# else:\n",
        "#   n = 1\n",
        "#   max_gen_length = 2000 if model_cfg['word_level'] else 10000\n",
        "  \n",
        "timestring = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "gen_file = '{}_gentext_{}.txt'.format(model_name, timestring)\n",
        "\n",
        "textgen.generate_to_file(gen_file,\n",
        "                         temperature=temperature,\n",
        "                         prefix=prefix,\n",
        "                         n=5,\n",
        "                         max_gen_length=9)\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w2hhsFf6EkZ",
        "colab_type": "text"
      },
      "source": [
        "# Saving the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvJdtlRR6Gy0",
        "colab_type": "text"
      },
      "source": [
        "When we trained the model, `textgenrnn` saved the weights, vocabulary, and configuration that resulted from the training to separate files.  Each of those files has a prefix of the `model_name` that we defined earlier in the code.\n",
        "\n",
        "We can download these files so that they can be loaded into a new `textgenrnn` model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLyldAx7vU4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.download('{}_weights.hdf5'.format(model_name))\n",
        "files.download('{}_vocab.json'.format(model_name))\n",
        "files.download('{}_config.json'.format(model_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCFPmyLxmA7Q",
        "colab_type": "text"
      },
      "source": [
        "#Future Work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-SeUDIrmDbq",
        "colab_type": "text"
      },
      "source": [
        "*   Addressing non-binary names\n",
        "*   Run model in a loop with different epochs and visualize results\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhrgmtABmCPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}